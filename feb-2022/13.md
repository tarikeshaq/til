# Sunday, February 13th

## What is Strategy
One of the most (if not most) popular HBR articles is Micheal Porter's [*What Is Strategy*](https://hbr.org/1996/11/what-is-strategy)

I had read summaries of it in the past, but I thought it's time I read the actual thing. To get good understanding of it, I tried to read it thoughtfully, and I'm only a quarter through

### A quick reminder
The goal of profit-seeking corporations is simple, it's **sustainable profitability**. If you tell a company that they'll be cash-flow positive until the end of time they'll be happy. It was good to set this understanding up at the start because the discussion on strategy all leads up to sustainable profitability.

Additionally, a reminder that a competitive advantage is captured in either:
- Producing a comparative value to competition, at a reduced cost
- Providing a greater value than the competition, thus allowing a higher price

Sometimes you see both, and the idea is really simple. Profit = Revenue - Cost. Greater value means flexibility in pricing, so revenue goes up, reduced cost means cost goes down. Both increase profits.

### Strategy vs Operational Efficiency
I'll define strategy in a bit, but the big idea is that operational efficiency and strategy are different. When companies optimize their supply chains, implement good internal processes, outsource work, etc - they are improving their operational efficiency and **not** creating strategy.

#### It's all about activities
More on this later and as I finish reading the article, but I like the articles framing of everything being based on *activities* it still feels weird but it generalizes things well. When companies have a cost advantage, they typically are doing their activities more efficiently, and when they have a price advantage, they are pretty much choosing the right activities to provide more value.

#### The productivity frontier
The idea of a productivity frontier is that it's the **highest possible value** activities can produce given the **best possible resources**. You can have productivity frontiers for specific activities (like for example given technology, what is the most possible number of units of X can you get from your suppliers). You can also have productivity frontiers for products that companies make. 

When a company improves its operational efficiency, what it's doing is increasing the productivity frontier for it's products/services. Meaning it's raising the bar for everyone in the industry. In other words, it's competitors will catch on pretty quickly! That doesn't get us our goal of **sustainable** profitability, at best it's temporary.

### Operational Efficiency is essential, but not sufficient
It's clear why operational efficiency is essential - you will be out-competed pretty quickly as competitors charge less and undercut you, or are able to price higher and produce more value.

But it's not sufficient on it's own for the following reasons:
- Diffusion: As you do your activities more efficiently, competitors will follow and your operational efficiency will diffuse to your competitors
- Competitive convergence: Once it's a game of operational efficiency, all competitors will be locked in a game of getting closer to the frontier. Meaning companies will converge and profitability will suffer.

### So really, what is strategy?
Strategy is deliberately choosing a mix of activities that are **different** from competitors, in order to produce a new mix of value.

I'll stop here. The article had a couple of amazing examples I'm still reflecting on, I'll write more on this on later update.

## Experimentation at Netflix
Half my time at work is spent working on the client side of a new experimentation platform, so I was ecstatic to see a series about experimentation at Netflix, ending with an amazing article about [Netflix's Culture of Learning](https://netflixtechblog.com/netflix-a-culture-of-learning-394bc7d0f94c)

Today I read three of those articles, I had previously read the first three, and I ended up skipping the 6th one and reading the last one instead.

### Article 4: False Negatives and Power
I learned about the concept of Power in statistics. Power is the probability that your study can correctly reject the null hypothesis given the experiment design. Most importantly from the article I learned that power is really important - the higher the power the more confident you are in the results of the experiment. You can't easily tell the power, you almost need tons of experience in the domain, however, you should always aim to increase it.

To increase power you can:
- Increase effect size: Increase the difference in metrics impact between the treatment and the control group. This can be done by designing the experiment on surfaces that have the potential for large improvement in the relevant metrics for example
- Increase sample size: The higher the sample size, the more the results will converge the less the false negative rate, the higher the power!
- Lower the variability of the metrics: If you can control your population so that the variability in the metrics is low, then you will have a higher power

### Article 5: Decision making with experimentation
There are a few important bullet points here - First, the principles that Netflix follow when it comes to looking at experiment results:
1. Proper Inference requires full reporting and transparency: This means reporting **both** studies that yielded significant results and those that didn't. Because those that did might have been false positives...
1. P-value or statistical significance does not measure the size of an effect or importance of the result: The importance of the result should be determined independently based on the product, its requirements, the metrics and the costs involved. It's a separate exercise.
1. Scientific decisions and business and policy decisions should be based **only** on whether the p-value passes a threshold: This is similar to the above, false positives are possible and the importance of the decision is not dictated by the p-value.

So, given the above, what criteria must the results pass for them to lead to a decision?
1. Does the result align with the hypothesis: Even if the p-value passes the threshold, is the result metric change relevant to they hypothesis? Are we getting an increase in engagement when the hypothesis had nothing user facing in it?
1. Does the metric story flow: What do the secondary metric changes look like? Do they flow well with the main metrics? Are there other metrics that are impacted in an unusual way? is there something that feels *off* about the results?
1. Is there additional supporting or refuting evidence? What else can we tell from past experiments, etc? Are variants of the experiment returning different results?
1. Do results repeat: If we repeat the experiment, did it return the same results?

### Article 7: A culture of learning
I loved this article, it highlights a culture of continuos improvement using proper data-driven experimentation. I was reading this using the lens of someone who wants to instill this culture in himself and learn how to share it broadly.. 

It seems to me the in order to properly benefit from experimentation it needs to be core to the culture of the organization. Which means:
- Leadership buy in into experimentation and the value of A/B experiments
- Building trust in the results of the tests and the system that supports them
- Building the technical capabilities to run experiments at scale

Netflix did an amazing job at this, but they've been doing it for 20 years now. It's a core to their culture. I'm interested to see how other orgs where it isn't, integrate it successfully given competing priorities.

I also loved how Netflix has Experimentation classes and tools to teach teams how use the experimentation platform...
